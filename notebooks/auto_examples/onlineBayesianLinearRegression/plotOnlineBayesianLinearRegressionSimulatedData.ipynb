{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simulated data\n\nThe code below uses an online algorithm to estimate the posterior of the weighs\nof a linear regression model using simulate data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import requirments\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport scipy.stats\nimport plotly.subplots\nimport plotly.graph_objects as go\n\nimport lds.inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define data generation variables\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 20\na0 = -0.3\na1 = 0.5\nlikelihood_precision_coef = (1/0.2)**2\nn_samples_to_plot = (1, 2, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = np.random.uniform(low=-1, high=1, size=n_samples)\ny = a0 + a1 * x\nt = y + np.random.standard_normal(size=y.shape) * 1.0/likelihood_precision_coef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define plotting variables\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_post_samples = 6\nmarker_true = \"cross\"\nsize_true = 10\ncolor_true = \"white\"\nmarker_data = \"circle-open\"\nsize_data = 10\ncolor_data = \"blue\"\nline_width_data = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define estimation variables\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_precision_coef = 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Kalman filter matrices\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "B = np.eye(N=2)\nQ = np.zeros(shape=((2,2)))\nR = np.array([[1.0/likelihood_precision_coef]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate and plot posterior\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_grid = np.linspace(-1, 1, 100)\ny_grid = np.linspace(-1, 1, 100)\nX_grid, Y_grid = np.meshgrid(x_grid, y_grid)\npos = np.dstack((X_grid, Y_grid))\n\nPhi = np.column_stack((np.ones(len(x)), x))\n\n# set prior\nm0 = np.array([0.0, 0.0])\nS0 = 1.0 / prior_precision_coef * np.eye(2)\n\nfig = plotly.subplots.make_subplots(rows=len(n_samples_to_plot)+1, cols=3)\nx_dense = np.arange(-1.0, 1.0, 0.1)\n\n# trace true coefficient\ntrace_true_coef = go.Scatter(x=[a0], y=[a1], mode=\"markers\",\n                             marker_symbol=marker_true,\n                             marker_size=size_true,\n                             marker_color=color_true,\n                             name=\"true mean\",\n                             showlegend=False)\n\nrv = scipy.stats.multivariate_normal(m0, S0)\n\n# plot prior\nZ = rv.pdf(pos)\ntrace_post = go.Contour(x=x_grid, y=y_grid, z=Z, showscale=False)\nfig.add_trace(trace_post, row=1, col=2)\n\nfig.add_trace(trace_true_coef, row=1, col=2)\n\nfig.update_xaxes(title_text=\"Intercept\", row=1, col=2)\nfig.update_yaxes(title_text=\"Slope\", row=1, col=2)\n# sample from prior\nsamples = rv.rvs(size=n_post_samples)\n\n# plot regression lines corresponding to samples\nfor a_sample in samples:\n    sample_intercept, sample_slope = a_sample\n    sample_y = sample_intercept + sample_slope * x_dense\n    trace = go.Scatter(x=x_dense, y=sample_y, mode=\"lines\",\n                       line_color=\"red\", showlegend=False)\n    fig.add_trace(trace, row=1, col=3)\nfig.update_xaxes(title_text=\"x\", row=1, col=3)\nfig.update_yaxes(title_text=\"y\", row=1, col=3)\n\nmn = m0\nSn = S0\nkf = lds.inference.TimeVaryingOnlineKalmanFilter()\n\nfor n, t in enumerate(y):\n    print(f\"Processing {n}/({len(y)})\")\n    # update posterior\n    mn, Sn = kf.predict(x=mn, P=Sn, B=B, Q=Q)\n    mn, Sn = kf.update(y=t, x=mn, P=Sn, Z=Phi[n, :].reshape((1, Phi.shape[1])), R=R)\n\n    if n+1 in n_samples_to_plot:\n        index_sample = n_samples_to_plot.index(n+1)\n        # compute likelihood\n        Z = np.empty(shape=(len(x_grid), len(y_grid)), dtype=np.double)\n        for i, w0 in enumerate(x_grid):\n            for j, w1 in enumerate(y_grid):\n                rv = scipy.stats.norm(w0 + w1 * x[n],\n                                      1.0/likelihood_precision_coef)\n                Z[j, i] = rv.pdf(t)\n\n        # plot likelihood\n        trace_like = go.Contour(x=x_grid, y=y_grid, z=Z, showscale=False)\n        fig.add_trace(trace_like, row=index_sample+2, col=1)\n\n        fig.add_trace(trace_true_coef, row=index_sample+2, col=1)\n\n        fig.update_xaxes(title_text=\"Intercept\", row=index_sample+2, col=1)\n        fig.update_yaxes(title_text=\"Slope\", row=index_sample+2, col=1)\n\n        rv = scipy.stats.multivariate_normal(mn, Sn)\n\n        # plot updated posterior\n        Z = rv.pdf(pos)\n        trace_post = go.Contour(x=x_grid, y=y_grid, z=Z, showscale=False)\n        fig.add_trace(trace_post, row=index_sample+2, col=2)\n\n        fig.add_trace(trace_true_coef, row=index_sample+2, col=2)\n\n        fig.update_xaxes(title_text=\"Intercept\", row=index_sample+2, col=2)\n        fig.update_yaxes(title_text=\"Slope\", row=index_sample+2, col=2)\n\n        # sample from posterior\n        samples = rv.rvs(size=n_post_samples)\n\n        # plot regression lines corresponding to samples\n        for a_sample in samples:\n            sample_intercept, sample_slope = a_sample\n            sample_y = sample_intercept + sample_slope * x_dense\n            trace = go.Scatter(x=x_dense, y=sample_y, mode=\"lines\",\n                               line_color=\"red\", showlegend=False)\n            fig.add_trace(trace, row=index_sample+2, col=3)\n        trace_data = go.Scatter(x=x[:(n+1)], y=y[:(n+1)],\n                                mode=\"markers\",\n                                marker_symbol=marker_data,\n                                marker_size=size_data,\n                                marker_color=color_data,\n                                marker_line_width=line_width_data,\n                                showlegend=False,\n                               )\n        fig.add_trace(trace_data, row=index_sample+2, col=3)\n        fig.update_xaxes(title_text=\"x\", row=index_sample+2, col=3)\n        fig.update_yaxes(title_text=\"y\", row=index_sample+2, col=3)\n\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}